# deep-learning-neural-net-01
Aborda o problema de classifica√ß√£o de d√≠gitos manuscritos do MNIST usando a arquitetura de rede neural InceptionV3. Conclui-se que a combina√ß√£o do InceptionV3 e transfer√™ncia de aprendizado permite a constru√ß√£o de um classificador eficaz para o MNIST.
---

## **Descri√ß√£o Geral**
O problema consiste em classificar corretamente d√≠gitos manuscritos (0-9) a partir de imagens em escala de cinza, com dimens√µes de 28x28 pixels. O conjunto de dados MNIST √© amplamente usado como benchmark em aprendizado de m√°quina.

O c√≥digo utiliza a biblioteca **PyTorch** para constru√ß√£o e treinamento do modelo.

---

## **Se√ß√µes do C√≥digo**

### **1. Bibliotecas Utilizadas**
As principais bibliotecas empregadas no c√≥digo s√£o:
- **`numpy`**: Para opera√ß√µes matem√°ticas e manipula√ß√£o de dados.
- **`torch`** e **`torchvision`**: Para constru√ß√£o, treinamento e manipula√ß√£o de redes neurais.
- **`matplotlib.pyplot`**: Para visualiza√ß√£o de dados.
- **`time`**: Para medir a dura√ß√£o do treinamento.

---

### **2. Pr√©-processamento dos Dados**
- **Transforma√ß√£o**: As imagens s√£o convertidas para tensores com `transforms.ToTensor()`.
- **Carregamento**: Utiliza-se `torchvision.datasets.MNIST` para carregar os datasets de treino e valida√ß√£o.
- **Buffers de dados**: Os datasets s√£o divididos em lotes de tamanho 64 e embaralhados para o treinamento utilizando `DataLoader`.

---

### **3. Visualiza√ß√£o Inicial**
Uma amostra da imagem √© exibida usando `plt.imshow` para confirmar que os dados est√£o corretamente carregados.

---

### **4. Estrutura da Rede Neural**
A rede implementada possui tr√™s camadas principais:
1. **Camada de Entrada**: Conecta 784 neur√¥nios (28x28 pixels) a 128 neur√¥nios.
2. **Camada Intermedi√°ria**: Conecta 128 neur√¥nios a 64.
3. **Camada de Sa√≠da**: Conecta 64 neur√¥nios a 10, representando os d√≠gitos de 0 a 9.

#### **Detalhes Adicionais**
- **Fun√ß√£o de ativa√ß√£o**: A ReLU √© usada nas camadas de entrada e intermedi√°ria.
- **Fun√ß√£o de sa√≠da**: LogSoftmax, para calcular a probabilidade logar√≠tmica dos d√≠gitos.

---

### **5. Treinamento do Modelo**
A fun√ß√£o `treino` executa as seguintes etapas:
- Define o otimizador **SGD (Stochastic Gradient Descent)** com:
  - Taxa de aprendizado: `0.01`
  - Momentum: `0.5`
- Utiliza a fun√ß√£o de perda **NLLLoss (Negative Log Likelihood)**.
- Realiza o treinamento por **10 √©pocas**, calculando a perda em cada itera√ß√£o e ajustando os pesos e vieses da rede.

---

### **6. Valida√ß√£o do Modelo**
A fun√ß√£o `validacao`:
- Desativa o autograd (para maior desempenho na valida√ß√£o).
- Faz previs√µes sobre os dados de valida√ß√£o.
- Compara as previs√µes com os r√≥tulos reais e calcula a precis√£o.

---

### **7. Configura√ß√£o e Execu√ß√£o**
- O modelo √© movido para a GPU, caso dispon√≠vel, utilizando `torch.device`.
- A classe `Modelo` √© instanciada e passada para as fun√ß√µes de treinamento e valida√ß√£o.

---

## **Resumo Final**
O script implementa uma rede neural densa simples para resolver o problema de classifica√ß√£o de d√≠gitos manuscritos no MNIST. Embora o texto mencione o modelo **InceptionV3**, ele n√£o √© implementado diretamente. 

Se precisar de mais informa√ß√µes sobre como executar, modificar ou expandir este c√≥digo, estou √† disposi√ß√£o para ajudar! üòä
